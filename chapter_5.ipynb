{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 卷积神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D_V0(nn.Module):\n",
    "    def __init__(self, kernel_size, weight_attr=None):\n",
    "        super(Conv2D_V0, self).__init__()\n",
    "        if weight_attr is None:\n",
    "            self.weight = nn.Parameter(data=nn.init.constant_(torch.empty(kernel_size, kernel_size), val=1.))\n",
    "        else:\n",
    "            self.weight = weight_attr\n",
    "    \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        input:\n",
    "            X: shape=[B, N, M]\n",
    "        \"\"\"\n",
    "        u, v = self.weight.shape\n",
    "        output = torch.zeros([X.shape[0], X.shape[1] - u + 1, X.shape[2] - v + 1])\n",
    "        for i in range(output.shape[1]):\n",
    "            for j in range(output.shape[2]):\n",
    "                output[:, i, j] = torch.sum(X[:, i:i+u, j:j+v] * self.weight, dim=[1, 2])\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: tensor([[[ 0.1268,  1.3564, -0.0247],\n",
      "         [-0.8466,  0.0293, -0.5721],\n",
      "         [-1.2546,  0.0486,  0.2753]],\n",
      "\n",
      "        [[-2.1550, -0.7116,  0.0575],\n",
      "         [ 0.6263, -1.7736, -0.2205],\n",
      "         [ 2.7467, -1.0480,  1.1239]]]), \n",
      "output: tensor([[[ 0.6659,  0.7890],\n",
      "         [-2.0233, -0.2189]],\n",
      "\n",
      "        [[-4.0138, -2.6481],\n",
      "         [ 0.5514, -1.9181]]], grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(100)\n",
    "inputs = torch.randn([2, 3, 3])\n",
    "conv2d = Conv2D_V0(kernel_size=2)\n",
    "outputs = conv2d(inputs)\n",
    "print(f\"input: {inputs}, \\noutput: {outputs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, kernel_size, stride=1, padding=0, weight_attr=None):\n",
    "        super(Conv2d, self).__init__()\n",
    "        if weight_attr is None:\n",
    "            self.weight = nn.Parameter(data=nn.init.constant_(torch.empty(kernel_size, kernel_size), val=1.))\n",
    "        else:\n",
    "            self.weight = nn.Parameter(data=weight_attr)\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "    \n",
    "    def forward(self, X):\n",
    "        new_X = torch.zeros([X.shape[0], X.shape[1] + self.padding * 2, X.shape[2] + self.padding * 2])\n",
    "        new_X[:, self.padding:self.padding + X.shape[1], self.padding:self.padding + X.shape[2]] = X\n",
    "        u, v = self.weight.shape\n",
    "        output_h = (new_X.shape[1] - u) // self.stride + 1\n",
    "        output_w = (new_X.shape[2] - v) // self.stride + 1\n",
    "        output = torch.zeros([X.shape[0], output_h, output_w])\n",
    "        for i in range(output.shape[1]):\n",
    "            for j in range(output.shape[2]):\n",
    "                output[:, i, j] = torch.sum(new_X[:, i * self.stride:i * self.stride + u, j * self.stride:j * self.stride + v]\n",
    "                                            * self.weight, dim=[1, 2])\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: input shape: torch.Size([2, 8, 8]), output shape: torch.Size([2, 8, 8])\n",
      "2: input shape: torch.Size([2, 8, 8]), output shape: torch.Size([2, 4, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn([2, 8, 8])\n",
    "conv2d_padding = Conv2d(kernel_size=3, padding=1)\n",
    "outputs = conv2d_padding(inputs)\n",
    "print(f\"1: input shape: {inputs.shape}, output shape: {outputs.shape}\")\n",
    "conv2d_stride = Conv2d(kernel_size=3, stride=2, padding=1)\n",
    "outputs = conv2d_stride(inputs)\n",
    "print(f\"2: input shape: {inputs.shape}, output shape: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "inputs: tensor([[[  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,   3.,\n",
      "            0.,   0.,   4.,   2.,   0.,  11.,   0.,   0.,  14.,   1.,   0.,\n",
      "           19.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,   0.,\n",
      "            0.,   7.,   0.,   1.,  10.,   0.,   2.,   2.,  16.,   0.,   3.,\n",
      "            3.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7.,   8.,   0.,\n",
      "            8.,   0.,   0.,   8.,   0.,   0.,  19.,   0.,   0.,   1.,  21.,\n",
      "            0.,   4.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   1.,\n",
      "            0.,   0.,   1.,   0.,   0.,   0.,   0.,   0.,  11.,   0.,   0.,\n",
      "           10.,   3.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,  13.,   0.,  15.,\n",
      "           10.,  26.,  34.,  17.,  77., 181., 178.,  35.,   4.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 150.,\n",
      "          254., 250., 251., 243., 252., 252., 255.,  45.,   6.,   0.,   5.,\n",
      "            0.,   9.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   7.,  72., 205.,\n",
      "          255., 238., 243., 255., 254., 251., 248., 201., 198.,  57.,   0.,\n",
      "           19.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0., 218., 255.,\n",
      "          241., 255., 249., 250., 251., 250., 255., 255., 242., 224.,  49.,\n",
      "            0.,  12.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   1.,   2.,   3.,   2.,   2.,   1.,   0.,  65., 228.,\n",
      "          255., 254., 244., 119.,  34.,  41., 110., 250., 255., 248., 124.,\n",
      "           20.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,  12.,   0.,  62.,\n",
      "          103., 113., 117.,  34.,   0.,   0.,   0., 200., 244., 255., 255.,\n",
      "            0.,  12.,   0.,   0.,   0.,   0.],\n",
      "         [  2.,   1.,   0.,   0.,   0.,   0.,   1.,   2.,   0.,   0.,   2.,\n",
      "            4.,   0.,  11.,   0.,   7.,   6.,   0.,  75., 244., 255., 255.,\n",
      "            4.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   1.,   2.,   3.,   4.,   4.,   0.,  14.,   0.,\n",
      "            0.,   0.,   9.,   0.,   2.,   0.,   0.,  34., 255., 255., 253.,\n",
      "           10.,  10.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   1.,   2.,   3.,   2.,   0.,   0.,   3.,   2.,   0.,\n",
      "           13.,  11.,   0.,   0.,   0.,   6.,  12.,  99., 255., 254., 248.,\n",
      "           15.,  12.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   1.,   1.,   1.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,\n",
      "            0.,   5.,   6.,  11.,   0.,   0.,  17., 184., 247., 255., 243.,\n",
      "           13.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  3.,   2.,   0.,   0.,   0.,   0.,   2.,   4.,   4.,   0.,  11.,\n",
      "            0.,  51.,  94.,  85.,   5.,   5.,  25., 246., 246., 255., 208.,\n",
      "            0.,   9.,   0.,   0.,   0.,   0.],\n",
      "         [  4.,   1.,   0.,   0.,   1.,   7.,  15.,  19.,  99., 103., 182.,\n",
      "          189., 237., 253., 252., 191., 190., 227., 243., 252., 210.,  18.,\n",
      "            7.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   4.,   0.,   0.,  32., 109., 185., 247., 255., 242., 255.,\n",
      "          244., 255., 255., 242., 251., 255., 240., 255., 255., 218., 124.,\n",
      "            9.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  2.,   0.,   0.,   0., 127., 255., 235., 255., 255., 247., 229.,\n",
      "          212., 242., 250., 255., 255., 248., 255., 253., 249., 255., 243.,\n",
      "          170.,  12.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,  11.,   0.,   9., 253., 255., 255., 233., 202.,  85.,   0.,\n",
      "           53., 196., 238., 255., 227., 238., 142., 109., 193., 255., 240.,\n",
      "          255., 180.,   0.,   0.,   0.,   0.],\n",
      "         [  6.,   0.,  22.,   1., 245., 243., 254., 255., 217., 235., 226.,\n",
      "          213., 244., 251., 255., 239.,  77.,   0.,   0.,  20., 182., 247.,\n",
      "          239., 243.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   4., 165., 251., 255., 245., 255., 242., 253.,\n",
      "          250., 255., 197., 107.,  59.,   0.,  18.,   2.,   6.,   0.,  54.,\n",
      "          255., 158.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,  24.,   0.,   0.,   6.,  34., 167., 194., 176., 183., 164.,\n",
      "           44.,   2.,  10.,   6.,   6.,   0.,   0.,   5.,   0.,   1.,   0.,\n",
      "           14.,   2.,   0.,   0.,   0.,   0.],\n",
      "         [ 10.,   0.,  14.,   0.,  12.,   0.,   5.,   0.,   1.,   0.,   6.,\n",
      "            0.,   7.,   0.,   0.,   0.,   8.,   0.,  10.,   0.,   5.,   0.,\n",
      "            0.,  10.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,  14.,   0.,   4.,   0.,   0.,  25.,   0.,   0.,   9.,   0.,\n",
      "            0.,   9.,   0.,  11.,   0.,   1.,   0.,   0.,   2.,   0.,   0.,\n",
      "            7.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.],\n",
      "         [  0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "            0.,   0.,   0.,   0.,   0.,   0.]]])\n",
      "output: tensor([[[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -7.0000e+00, -2.8000e+01,  7.7000e+01, -3.2000e+01,\n",
      "          -1.8000e+01,  4.4000e+01, -2.2000e+01, -1.6000e+01,  5.8000e+01,\n",
      "          -4.2000e+01, -1.6000e+01, -3.5000e+01,  1.1000e+02, -5.6000e+01,\n",
      "          -2.1000e+01, -2.3000e+01, -2.6000e+01, -4.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -7.0000e+00,  3.6000e+01,  4.4000e+01, -2.9000e+01,\n",
      "           5.6000e+01, -1.6000e+01, -1.7000e+01,  5.2000e+01, -1.9000e+01,\n",
      "          -3.1000e+01,  1.4800e+02, -5.0000e+01, -3.0000e+01, -4.3000e+01,\n",
      "           1.5100e+02, -4.4000e+01,  1.6000e+01, -7.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -2.0000e+01, -2.8000e+01, -4.4000e+01, -3.3000e+01,\n",
      "          -6.0000e+01, -7.9000e+01, -7.7000e+01, -1.3700e+02, -2.8300e+02,\n",
      "          -4.5500e+02, -4.1300e+02, -2.4700e+02,  4.8000e+01, -3.7000e+01,\n",
      "          -3.2000e+01,  5.2000e+01,  1.0000e+01, -7.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -1.3000e+01,  1.0400e+02, -1.7900e+02, -2.9500e+02,\n",
      "          -6.1600e+02, -5.9200e+02, -5.1600e+02, -7.2200e+02, -3.2900e+02,\n",
      "           4.3400e+02,  6.5600e+02, -2.1900e+02, -6.5000e+01, -2.6000e+01,\n",
      "          -1.5000e+01, -2.7000e+01, -2.2000e+01, -1.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -2.0000e+01, -9.2000e+01, -4.6200e+02,  3.8900e+02,\n",
      "           8.8300e+02,  6.8900e+02,  7.0200e+02,  5.6100e+02,  4.8600e+02,\n",
      "           3.2000e+02,  6.4900e+02, -7.6500e+02, -4.9200e+02, -2.7000e+02,\n",
      "          -3.6000e+01, -3.3000e+01,  5.3000e+01, -9.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00, -7.0000e+00, -2.3400e+02, -2.5900e+02,  1.9500e+02,\n",
      "           1.9200e+02, -9.4000e+01, -4.7000e+01,  4.7000e+01,  2.8000e+01,\n",
      "          -9.0000e+00,  2.2000e+02,  1.0400e+02,  5.5400e+02, -2.6800e+02,\n",
      "          -3.5400e+02,  7.7000e+01, -4.0000e+01, -2.1000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-1.0000e+00, -3.0000e+00, -6.0000e+00, -7.0000e+00, -7.0000e+00,\n",
      "          -5.0000e+00, -1.0000e+01, -3.6300e+02,  9.1200e+02,  5.0100e+02,\n",
      "          -1.7000e+01,  6.1000e+01,  1.3400e+02,  3.5100e+02,  5.5400e+02,\n",
      "           5.5600e+02,  4.3400e+02,  2.8100e+02,  2.4800e+02,  6.1900e+02,\n",
      "          -3.0000e+02, -2.2400e+02,  5.7000e+01, -1.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-3.0000e+00,  5.0000e+00,  1.2000e+01,  2.0000e+01,  1.1000e+01,\n",
      "           1.3000e+01, -6.0000e+00, -2.9600e+02, -2.5500e+02,  6.2500e+02,\n",
      "           5.2900e+02,  4.5500e+02,  5.6100e+02, -2.2700e+02, -6.7300e+02,\n",
      "          -5.7200e+02, -3.7100e+02,  4.3900e+02,  1.2200e+02,  3.3600e+02,\n",
      "          -5.9000e+01, -2.9200e+02, -4.4000e+01, -2.4000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 3.0000e+00, -5.0000e+00, -6.0000e+00, -7.0000e+00, -8.0000e+00,\n",
      "          -8.0000e+00, -1.8000e+01,  2.8000e+01, -3.6900e+02, -1.6100e+02,\n",
      "          -9.4000e+01, -8.4000e+01,  1.6100e+02, -2.6000e+02, -2.4100e+02,\n",
      "          -1.9800e+02, -6.8200e+02,  4.2200e+02,  1.7000e+02,  1.6000e+02,\n",
      "           8.7900e+02, -6.7000e+02,  7.2000e+01, -1.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 4.0000e+00, -3.0000e+00, -3.0000e+00, -6.0000e+00, -1.0000e+01,\n",
      "          -5.0000e+00, -5.0000e+00, -3.2000e+01, -9.0000e+01, -1.6700e+02,\n",
      "          -2.4800e+02, -3.5700e+02, -1.8500e+02, -1.8000e+02,  1.4000e+01,\n",
      "           3.9000e+01, -3.1500e+02, -3.7700e+02,  3.7900e+02,  2.4000e+01,\n",
      "           7.5300e+02, -7.6300e+02, -3.6000e+01, -2.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-4.0000e+00, -5.0000e+00,  0.0000e+00,  5.0000e+00,  1.2000e+01,\n",
      "           2.0000e+01,  2.2000e+01, -2.5000e+01,  1.0500e+02, -3.5000e+01,\n",
      "          -3.0000e+01, -4.8000e+01,  5.0000e+01, -2.9000e+01, -3.0000e+00,\n",
      "          -3.3000e+01, -2.3200e+02, -6.6800e+02,  5.6900e+02,  2.1000e+01,\n",
      "           7.2800e+02, -7.1700e+02,  3.9000e+01, -2.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-3.0000e+00,  2.0000e+00,  7.0000e+00,  1.3000e+01,  4.0000e+00,\n",
      "          -1.3000e+01, -1.2000e+01,  2.0000e+00, -3.0000e+00, -3.0000e+01,\n",
      "           8.8000e+01,  5.5000e+01, -4.2000e+01, -2.8000e+01, -1.9000e+01,\n",
      "           1.7000e+01, -2.4400e+02, -2.1200e+02,  4.5700e+02,  2.1000e+01,\n",
      "           6.8600e+02, -6.6900e+02,  4.8000e+01, -2.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 1.0000e+00,  1.0000e+00,  1.0000e+00, -8.0000e+00, -7.0000e+00,\n",
      "          -8.0000e+00, -1.4000e+01, -6.0000e+00, -1.3000e+01, -2.7000e+01,\n",
      "          -9.1000e+01, -1.3500e+02, -2.0900e+02, -1.0200e+02, -1.1200e+02,\n",
      "          -7.0000e+01, -4.4100e+02,  3.2500e+02,  1.8200e+02,  8.4000e+01,\n",
      "           6.9600e+02, -6.3100e+02, -4.9000e+01, -2.1000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 6.0000e+00, -6.0000e+00, -3.0000e+00, -9.0000e+00, -2.5000e+01,\n",
      "          -2.9000e+01, -1.0800e+02, -1.9500e+02, -4.0100e+02, -3.8700e+02,\n",
      "          -6.7500e+02, -3.7600e+02, -1.4800e+02, -1.3200e+02, -6.9400e+02,\n",
      "          -6.1500e+02, -9.1200e+02,  5.2700e+02,  7.6000e+01,  3.6100e+02,\n",
      "           6.6300e+02, -4.9800e+02,  5.2000e+01, -9.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-5.0000e+00, -7.0000e+00, -3.3000e+01, -1.4000e+02, -2.8800e+02,\n",
      "          -4.5300e+02, -6.5900e+02, -8.2000e+01, -2.2400e+02,  4.1200e+02,\n",
      "           2.7700e+02,  5.5500e+02,  5.5300e+02,  6.4000e+02,  2.4300e+02,\n",
      "           3.2100e+02,  3.5700e+02,  1.9800e+02,  8.8000e+01,  1.0400e+02,\n",
      "          -8.8700e+02, -3.1200e+02, -2.5000e+01, -9.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 2.5000e+01, -5.0000e+00, -1.6000e+02, -2.4300e+02,  1.5000e+01,\n",
      "           3.3800e+02,  6.5800e+02,  5.7300e+02,  3.1100e+02,  3.9200e+02,\n",
      "           1.5100e+02,  1.5800e+02,  5.4000e+01, -2.6000e+01,  1.2000e+02,\n",
      "           1.8300e+02, -6.0000e+00,  6.6000e+01,  1.0500e+02,  1.3800e+02,\n",
      "          -1.3800e+02, -5.0200e+02, -1.9800e+02, -1.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-1.7000e+01, -2.4000e+01, -4.2100e+02,  1.0300e+02,  5.8900e+02,\n",
      "           8.6000e+01,  1.7300e+02,  2.7400e+02,  4.5300e+02,  4.9400e+02,\n",
      "           2.2200e+02,  2.3300e+02,  6.2000e+01,  6.7000e+01,  6.9000e+01,\n",
      "           1.2100e+02,  3.0000e+02,  3.2600e+02,  1.9900e+02,  2.6300e+02,\n",
      "           4.1800e+02,  2.9700e+02, -5.1800e+02, -1.9200e+02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 5.8000e+01, -4.3000e+01, -5.7600e+02,  8.8900e+02,  1.7300e+02,\n",
      "           5.5000e+01, -6.4000e+01, -1.6600e+02, -9.3100e+02, -1.5000e+03,\n",
      "          -1.1380e+03, -1.3500e+02, -4.4000e+01,  7.0000e+01, -6.0000e+00,\n",
      "           4.6100e+02, -4.4000e+01, -2.4000e+02,  2.2100e+02,  4.1100e+02,\n",
      "           7.4000e+01,  4.6600e+02,  5.2100e+02, -4.3500e+02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-3.9000e+01,  1.5100e+02, -6.9000e+02,  7.7900e+02,  1.1000e+01,\n",
      "           4.0000e+01,  1.2400e+02, -1.6000e+01,  4.0000e+02,  4.7700e+02,\n",
      "           2.2700e+02,  2.9900e+02,  2.6100e+02,  4.6700e+02,  6.9400e+02,\n",
      "          -3.0700e+02, -5.8600e+02, -4.9000e+02, -5.8700e+02,  4.4100e+02,\n",
      "           4.9600e+02,  2.8000e+02,  8.5700e+02, -5.8100e+02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-5.2000e+01, -5.1000e+01, -4.0700e+02,  5.3600e+02,  6.3900e+02,\n",
      "           3.9700e+02,  1.8700e+02,  2.9300e+02,  2.2700e+02,  4.6700e+02,\n",
      "           5.9900e+02,  8.2900e+02,  4.4600e+02, -1.6700e+02, -2.1800e+02,\n",
      "          -3.9900e+02,  6.0000e+01, -3.3000e+01, -1.6200e+02, -5.1000e+02,\n",
      "          -5.0600e+02,  1.0830e+03,  5.1100e+02, -4.0300e+02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 1.6800e+02, -4.2000e+01, -2.0100e+02, -4.1800e+02, -5.8900e+02,\n",
      "           3.5200e+02,  4.4800e+02,  2.8800e+02,  3.6700e+02,  3.3400e+02,\n",
      "          -5.8500e+02, -7.4700e+02, -4.9400e+02, -3.3100e+02, -1.3200e+02,\n",
      "          -9.1000e+01, -4.3000e+01,  4.0000e+00, -2.9000e+01, -5.7000e+01,\n",
      "          -3.2900e+02, -3.6700e+02, -4.2100e+02, -1.7000e+02,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-6.2000e+01,  7.0000e+01, -3.6000e+01,  5.2000e+01, -2.4900e+02,\n",
      "          -3.8000e+02, -5.6800e+02, -5.5400e+02, -5.3900e+02, -3.5200e+02,\n",
      "          -2.3200e+02, -9.0000e+00, -4.5000e+01, -3.3000e+01, -3.2000e+01,\n",
      "           5.7000e+01, -2.4000e+01,  7.3000e+01, -2.3000e+01,  3.7000e+01,\n",
      "          -2.7000e+01, -3.3000e+01,  5.7000e+01, -1.2000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 8.8000e+01, -3.2000e+01,  6.0000e+00, -1.6000e+01, -4.2000e+01,\n",
      "           1.9500e+02, -3.1000e+01, -1.0000e+01,  6.5000e+01, -1.5000e+01,\n",
      "          -2.2000e+01,  6.5000e+01, -2.7000e+01,  8.8000e+01, -2.0000e+01,\n",
      "           0.0000e+00, -1.9000e+01, -1.2000e+01,  1.0000e+00, -7.0000e+00,\n",
      "          -1.2000e+01,  4.6000e+01, -1.7000e+01, -1.0000e+01,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [-1.4000e+01, -1.8000e+01, -4.0000e+00, -4.0000e+00, -2.5000e+01,\n",
      "          -2.5000e+01, -2.5000e+01, -9.0000e+00, -9.0000e+00, -9.0000e+00,\n",
      "          -9.0000e+00, -9.0000e+00, -2.0000e+01, -1.1000e+01, -1.2000e+01,\n",
      "          -1.0000e+00, -1.0000e+00, -2.0000e+00, -2.0000e+00, -2.0000e+00,\n",
      "          -7.0000e+00, -7.0000e+00, -7.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           0.0000e+00]]], grad_fn=<CopySlices>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img = Image.open('./dataset/number.jpg')\n",
    "img = img.convert('L').resize((28, 28))\n",
    "w = torch.tensor([[-1., -1., -1.], [-1., 8., -1.], [-1., -1., -1.]])\n",
    "conv = Conv2d(kernel_size=3, stride=1, padding=0, weight_attr=w)\n",
    "\n",
    "inputs = np.asarray(img).astype('float32')\n",
    "inputs = torch.tensor(inputs)\n",
    "inputs = torch.unsqueeze(inputs, dim=0)\n",
    "print(inputs.shape)\n",
    "print(f'inputs: {inputs}')\n",
    "outputs = conv(inputs)\n",
    "print(f'output: {outputs}')\n",
    "outputs = outputs.detach().numpy()\n",
    "plt.figure(figsize=(8, 4))\n",
    "f = plt.subplot(121)\n",
    "f.set_title('input image', fontsize=15)\n",
    "plt.imshow(img)\n",
    "f = plt.subplot(122)\n",
    "f.set_title('output feature map', fontsize=15)\n",
    "plt.imshow(outputs.squeeze())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 基础算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,\n",
    "                 weight_attr=None, bias_attr=None):\n",
    "        super(Conv2D, self).__init__()\n",
    "        if weight_attr is None:\n",
    "            self.weight = nn.Parameter(data=nn.init.constant_(torch.empty(out_channels, in_channels, kernel_size, kernel_size), val=1.))\n",
    "        else:\n",
    "            self.weight = nn.Parameter(data=weight_attr(torch.empty(out_channels, in_channels, kernel_size, kernel_size)))\n",
    "        self.bias = nn.Parameter(data=torch.empty(out_channels, 1))\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "    \n",
    "    def single_forward(self, X, weight):\n",
    "        new_X = torch.zeros([X.shape[0], X.shape[1] + self.padding * 2, X.shape[2] + self.padding * 2])\n",
    "        new_X[:, self.padding:self.padding + X.shape[1], self.padding:self.padding + X.shape[2]] = X\n",
    "        u, v = weight.shape\n",
    "        output_h = (new_X.shape[1] - u) // self.stride + 1\n",
    "        output_w = (new_X.shape[2] - v) // self.stride + 1\n",
    "        output = torch.zeros([X.shape[0], output_h, output_w])\n",
    "        for i in range(output.shape[1]):\n",
    "            for j in range(output.shape[2]):\n",
    "                output[:, i, j] = torch.sum(new_X[:, i * self.stride:i * self.stride + u, j * self.stride:j * self.stride + v]\n",
    "                                            * weight, dim=[1, 2])\n",
    "        return output\n",
    "    \n",
    "    def multi2single_forward(self, inputs, weight, b):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "        - inputs: [B, D, M, N]\n",
    "        - weight: [D, U, V]\n",
    "        - b: [1]\n",
    "        \"\"\"\n",
    "        return torch.sum(torch.stack([self.single_forward(inputs[:, i, :, :], weight[i]) for i in range(self.in_channels)], dim=1), dim=1) + b\n",
    "    \n",
    "    def multi2multi_forward(self, inputs, weights, bias):\n",
    "        \"\"\"\n",
    "        输入：\n",
    "        - inputs: [B, D, M, N]\n",
    "        - weight: [P, D, U, V]\n",
    "        - b: [P, 1]\n",
    "        \"\"\"\n",
    "        return torch.stack([self.multi2single_forward(inputs, w, b) for w, b in zip(weights, bias)], dim=1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.multi2multi_forward(inputs, self.weight, self.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pool2D(nn.Module):\n",
    "    def __init__(self, size=(2, 2), mode='max', stride=1):\n",
    "        super(Pool2D, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.h, self.w = size\n",
    "        self.stride = stride\n",
    "    \n",
    "    def forward(self, X):\n",
    "        output_h = (X.shape[2] - self.h) // self.stride + 1\n",
    "        output_w = (X.shape[3] - self.w) // self.stride + 1\n",
    "        output = torch.zeros(size=[X.shape[0], X.shape[1], output_h, output_w])\n",
    "        for i in range(output.shape[2]):\n",
    "            for j in range(output.shape[3]):\n",
    "                if self.mode == 'max':\n",
    "                    output[:, :, i, j] = X[:, :, i * self.stride:i * self.stride + self.h,\n",
    "                                                     j * self.stride:j * self.stride + self.w].max()\n",
    "                elif self.mode == 'avg':\n",
    "                    output[:, :, i, j] = X[:, :, i * self.stride:i * self.stride + self.h,\n",
    "                                                     j * self.stride:j * self.stride + self.w].mean()\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 LeNet MNIST 任务（有点问题）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[123], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m fetch_openml\n\u001b[1;32m----> 2\u001b[0m mnist \u001b[38;5;241m=\u001b[39m \u001b[43mfetch_openml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmnist_784\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./dataset/MNIST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_openml.py:1118\u001b[0m, in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m   1116\u001b[0m \u001b[38;5;66;03m# obtain the data\u001b[39;00m\n\u001b[0;32m   1117\u001b[0m url \u001b[38;5;241m=\u001b[39m _DATA_FILE\u001b[38;5;241m.\u001b[39mformat(data_description[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m-> 1118\u001b[0m bunch \u001b[38;5;241m=\u001b[39m \u001b[43m_download_data_to_bunch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1120\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mas_frame\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopenml_columns_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd5_checksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_description\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmd5_checksum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_csv_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_csv_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_X_y:\n\u001b[0;32m   1135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bunch\u001b[38;5;241m.\u001b[39mdata, bunch\u001b[38;5;241m.\u001b[39mtarget\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_openml.py:669\u001b[0m, in \u001b[0;36m_download_data_to_bunch\u001b[1;34m(url, sparse, data_home, as_frame, openml_columns_info, data_columns, target_columns, shape, md5_checksum, n_retries, delay, parser, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01merrors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ParserError\n\u001b[0;32m    667\u001b[0m     no_retry_exception \u001b[38;5;241m=\u001b[39m ParserError\n\u001b[1;32m--> 669\u001b[0m X, y, frame, categories \u001b[38;5;241m=\u001b[39m \u001b[43m_retry_with_clean_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mno_retry_exception\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_load_arff_response\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    676\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopenml_columns_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_names_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    678\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_names_to_select\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_columns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    680\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmd5_checksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmd5_checksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    681\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m    \u001b[49m\u001b[43mread_csv_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread_csv_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Bunch(\n\u001b[0;32m    687\u001b[0m     data\u001b[38;5;241m=\u001b[39mX,\n\u001b[0;32m    688\u001b[0m     target\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m     target_names\u001b[38;5;241m=\u001b[39mtarget_columns,\n\u001b[0;32m    693\u001b[0m )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_openml.py:59\u001b[0m, in \u001b[0;36m_retry_with_clean_cache.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m URLError:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_openml.py:534\u001b[0m, in \u001b[0;36m_load_arff_response\u001b[1;34m(url, data_home, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, md5_checksum, n_retries, delay, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    524\u001b[0m arff_params: Dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m    525\u001b[0m     parser\u001b[38;5;241m=\u001b[39mparser,\n\u001b[0;32m    526\u001b[0m     output_type\u001b[38;5;241m=\u001b[39moutput_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    531\u001b[0m     read_csv_kwargs\u001b[38;5;241m=\u001b[39mread_csv_kwargs \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[0;32m    532\u001b[0m )\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 534\u001b[0m     X, y, frame, categories \u001b[38;5;241m=\u001b[39m \u001b[43m_open_url_and_load_gzip_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    535\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_home\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_retries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marff_params\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m parser \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_openml.py:522\u001b[0m, in \u001b[0;36m_load_arff_response.<locals>._open_url_and_load_gzip_file\u001b[1;34m(url, data_home, n_retries, delay, arff_params)\u001b[0m\n\u001b[0;32m    520\u001b[0m gzip_file \u001b[38;5;241m=\u001b[39m _open_openml_url(url, data_home, n_retries\u001b[38;5;241m=\u001b[39mn_retries, delay\u001b[38;5;241m=\u001b[39mdelay)\n\u001b[0;32m    521\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m closing(gzip_file):\n\u001b[1;32m--> 522\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_arff_from_gzip_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgzip_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marff_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_arff_parser.py:520\u001b[0m, in \u001b[0;36mload_arff_from_gzip_file\u001b[1;34m(gzip_file, parser, output_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape, read_csv_kwargs)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load a compressed ARFF file using a given parser.\u001b[39;00m\n\u001b[0;32m    471\u001b[0m \n\u001b[0;32m    472\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[38;5;124;03m    `output_array_type == \"pandas\"`.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m parser \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mliac-arff\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_liac_arff_parser\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgzip_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mopenml_columns_info\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_names_to_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    525\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_names_to_select\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m parser \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _pandas_arff_parser(\n\u001b[0;32m    530\u001b[0m         gzip_file,\n\u001b[0;32m    531\u001b[0m         output_type,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    535\u001b[0m         read_csv_kwargs,\n\u001b[0;32m    536\u001b[0m     )\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_arff_parser.py:197\u001b[0m, in \u001b[0;36m_liac_arff_parser\u001b[1;34m(gzip_file, output_arrays_type, openml_columns_info, feature_names_to_select, target_names_to_select, shape)\u001b[0m\n\u001b[0;32m    195\u001b[0m columns_to_keep \u001b[38;5;241m=\u001b[39m [col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns_to_select]\n\u001b[0;32m    196\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [first_df[columns_to_keep]]\n\u001b[1;32m--> 197\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m _chunk_generator(arff_container[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m], chunksize):\n\u001b[0;32m    198\u001b[0m     dfs\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m    199\u001b[0m         pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39mcolumns_names, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[columns_to_keep]\n\u001b[0;32m    200\u001b[0m     )\n\u001b[0;32m    201\u001b[0m \u001b[38;5;66;03m# dfs[0] contains only one row, which may not have enough data to infer to\u001b[39;00m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;66;03m# column's dtype. Here we use `dfs[1]` to configure the dtype in dfs[0]\u001b[39;00m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\utils\\__init__.py:729\u001b[0m, in \u001b[0;36m_chunk_generator\u001b[1;34m(gen, chunksize)\u001b[0m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03mchunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 729\u001b[0m     chunk \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    730\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunk:\n\u001b[0;32m    731\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m chunk\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\externals\\_arff.py:461\u001b[0m, in \u001b[0;36mDenseGeneratorData.decode_rows\u001b[1;34m(self, stream, conversors)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode_rows\u001b[39m(\u001b[38;5;28mself\u001b[39m, stream, conversors):\n\u001b[1;32m--> 461\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m stream:\n\u001b[0;32m    462\u001b[0m         values \u001b[38;5;241m=\u001b[39m _parse_values(row)\n\u001b[0;32m    464\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\externals\\_arff.py:864\u001b[0m, in \u001b[0;36mArffDecoder._decode.<locals>.stream\u001b[1;34m()\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstream\u001b[39m():\n\u001b[1;32m--> 864\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m s:\n\u001b[0;32m    865\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_line \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    866\u001b[0m         row \u001b[38;5;241m=\u001b[39m row\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\site-packages\\sklearn\\datasets\\_arff_parser.py:161\u001b[0m, in \u001b[0;36m_liac_arff_parser.<locals>._io_to_generator\u001b[1;34m(gzip_file)\u001b[0m\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_io_to_generator\u001b[39m(gzip_file):\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m gzip_file:\n\u001b[0;32m    162\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m line\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\gzip.py:390\u001b[0m, in \u001b[0;36mGzipFile.readline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadline\u001b[39m(\u001b[38;5;28mself\u001b[39m, size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_not_closed()\n\u001b[1;32m--> 390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbyte_view\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32md:\\miniconda3\\envs\\d2l_8\\lib\\gzip.py:487\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# Read a chunk of data from the file\u001b[39;00m\n\u001b[0;32m    485\u001b[0m buf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread(io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE)\n\u001b[1;32m--> 487\u001b[0m uncompress \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mprepend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decompressor\u001b[38;5;241m.\u001b[39munconsumed_tail)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', data_home='./dataset/MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mnist['data'].values\n",
    "target = mnist['target'].values\n",
    "train_set, dev_set, test_set = [data[:60000], target[:60000]], [data[60000:65000], target[60000:65000]], [data[65000:], target[65000:]]\n",
    "train_images, train_labels = train_set[0][:1000], train_set[1][:1000]\n",
    "dev_images, dev_labels = dev_set[0][:200], dev_set[1][:200]\n",
    "test_images, test_labels = test_set[0][:200], test_set[1][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = train_set[0][0], train_set[1][0]\n",
    "image, label = np.array(image).astype('float32'), int(label)\n",
    "\n",
    "image = np.reshape(image, [28, 28])\n",
    "image = Image.fromarray(image.astype('uint8'), mode='L')\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "preprocess = transforms.Compose([transforms.Resize(32), transforms.ToTensor(), transforms.Normalize(mean=[0.5], std=[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, dataset, transforms, mode='train') -> None:\n",
    "        super(MNISTDataset, self).__init__()\n",
    "        self.mode = mode\n",
    "        self.dataset = dataset\n",
    "        self.transforms = transforms\n",
    "        self.index_list = list(range(len(self.dataset[0])))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        index = self.index_list[index]\n",
    "        image, label = self.dataset[0][index], self.dataset[1][index]\n",
    "        image, label = np.array(image).astype('float32'), int(label)\n",
    "        image = np.reshape(image, [28, 28])\n",
    "        image = Image.fromarray(image.astype('uint8'), mode='L')\n",
    "        # image = self.transforms(image)\n",
    "        image = transforms.Resize(32)(image)\n",
    "        image = transforms.PILToTensor()(image).float()\n",
    "        image = transforms.Normalize(mean=[255.0/2], std=[255.0/2])(image)\n",
    "\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "train_dataset = MNISTDataset(dataset=train_set, transforms=preprocess, mode='train')\n",
    "test_dataset = MNISTDataset(dataset=test_set, transforms=preprocess, mode='test')\n",
    "dev_dataset = MNISTDataset(dataset=test_set, transforms=preprocess, mode='dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class Model_LeNet(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes=10) -> None:\n",
    "        super(Model_LeNet, self).__init__()\n",
    "        self.conv1 = Conv2D(in_channels=in_channels, out_channels=6, kernel_size=5, weight_attr=torch.nn.init.xavier_normal_)\n",
    "        self.pool2 = Pool2D(size=(2, 2), mode='max', stride=2)\n",
    "        self.conv3 = Conv2D(in_channels=6, out_channels=16, kernel_size=5, weight_attr=torch.nn.init.xavier_normal_)\n",
    "        self.pool4 = Pool2D(size=(2, 2), mode='avg', stride=2)\n",
    "        self.conv5 = Conv2D(in_channels=16, out_channels=120, kernel_size=5, weight_attr=torch.nn.init.xavier_normal_)\n",
    "        self.linear6 = nn.Linear(120, 84)\n",
    "        self.linear7 = nn.Linear(84, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = F.relu(self.conv1(x))\n",
    "        output = self.pool2(output)\n",
    "        output = F.relu(self.conv3(output))\n",
    "        output = self.pool4(output)\n",
    "        output = F.relu(self.conv5(output))\n",
    "        output = torch.squeeze(output, dim=[2, 3])\n",
    "        output = F.relu(self.linear6(output))\n",
    "        output = self.linear7(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.randn(*[1, 6, 28, 28])\n",
    "print(inputs)\n",
    "inputs = inputs.astype('float32')\n",
    "inputs = torch.tensor(inputs)\n",
    "model = Pool2D(size=(2, 2), mode='max', stride=2)\n",
    "outputs = model(inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.random.randn(*[1, 1, 32, 32])\n",
    "inputs = inputs.astype('float32')\n",
    "\n",
    "model = Model_LeNet(in_channels=1, num_classes=10)\n",
    "print(model.modules())\n",
    "model_modules = [x for x in model.modules()]\n",
    "print(model_modules)\n",
    "x = torch.tensor(inputs)\n",
    "for name, item in model.named_children():\n",
    "    try:\n",
    "        x = item(x)\n",
    "    except:\n",
    "        x = torch.reshape(x, [x.shape[0], -1])\n",
    "        x = item(x)\n",
    "    \n",
    "    if sum(1 for p in item.parameters()) == 2:\n",
    "        print(name, x.shape)\n",
    "        for p in item.parameters():\n",
    "            print(p.shape)\n",
    "    else:\n",
    "        print(name, x.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as opt\n",
    "from pre_methods import RunnerV3, Accuracy\n",
    "\n",
    "torch.manual_seed(100)\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "model = Model_LeNet(in_channels=1, num_classes=10)\n",
    "optimzer = opt.SGD(lr=0.1, params=model.parameters())\n",
    "loss_fn = F.cross_entropy\n",
    "metric = Accuracy(is_logist=True)\n",
    "\n",
    "runner = RunnerV3(model, optimizer=optimzer, loss_fn=loss_fn, metric=metric)\n",
    "runner.train(train_dataloader=train_loader, val_dataloader=dev_loader, num_epochs=5, log_steps=15, eval_steps=15, save_dir='./checkpoint_LeNet_MNIST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 ResNet MNIST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
